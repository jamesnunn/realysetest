I'm not in a position to create and test such large files but assuming hardware (RAM and disk space) is not a constraint, be it 
distributed or single node then I would guess at using Spark and creating an index on the files and running the join. The alternative 
using an RDB also uses an index but adds the overhead of having to load the data into tables before the index and join.
